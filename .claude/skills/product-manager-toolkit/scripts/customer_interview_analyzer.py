#!/usr/bin/envpython3"""CustomerInterviewAnalyzerExtractsinsights,patterns,andopportunitiesfromuserinterviews"""importrefromtypingimportDict,List,Tuple,SetfromcollectionsimportCounter,defaultdictimportjsonclassInterviewAnalyzer:"""Analyzecustomerinterviewsforinsightsandpatterns"""def__init__(self):#Painpointindicatorsself.pain_indicators=['frustrat','annoy','difficult','hard','confus','slow','problem','issue','struggle','challeng','pain','waste','manual','repetitive','tedious','boring','time-consuming','complicated','complex','unclear','wish','need','want']#Positiveindicatorsself.delight_indicators=['love','great','awesome','amazing','perfect','easy','simple','quick','fast','helpful','useful','valuable','save','efficient','convenient','intuitive','clear']#Featurerequestindicatorsself.request_indicators=['wouldbenice','wish','hope','want','need','should','could','wouldlove','ifonly','itwouldhelp','suggest','recommend','idea','whatif','haveyouconsidered']#Jobstobedonepatternsself.jtbd_patterns=[r'wheni\s+(.+?),\s+iwantto\s+(.+?)\s+sothat\s+(.+)',r'ineedto\s+(.+?)\s+because\s+(.+)',r'mygoalisto\s+(.+)',r'i\'mtryingto\s+(.+)',r'iuse\w+to\s+(.+)',r'helpsme\s+(.+)',]defanalyze_interview(self,text:str)->Dict:"""Analyzeasingleinterviewtranscript"""text_lower=text.lower()sentences=self._split_sentences(text)analysis={'pain_points':self._extract_pain_points(sentences),'delights':self._extract_delights(sentences),'feature_requests':self._extract_requests(sentences),'jobs_to_be_done':self._extract_jtbd(text_lower),'sentiment_score':self._calculate_sentiment(text_lower),'key_themes':self._extract_themes(text_lower),'quotes':self._extract_key_quotes(sentences),'metrics_mentioned':self._extract_metrics(text),'competitors_mentioned':self._extract_competitors(text)}returnanalysisdef_split_sentences(self,text:str)->List[str]:"""Splittextintosentences"""#Simplesentencesplittingsentences=re.split(r'[.!?]+',text)return[s.strip()forsinsentencesifs.strip()]def_extract_pain_points(self,sentences:List[str])->List[Dict]:"""Extractpainpointsfromsentences"""pain_points=[]forsentenceinsentences:sentence_lower=sentence.lower()forindicatorinself.pain_indicators:ifindicatorinsentence_lower:#Extractcontextaroundthepainpointpain_points.append({'quote':sentence,'indicator':indicator,'severity':self._assess_severity(sentence_lower)})breakreturnpain_points[:10]#Returntop10def_extract_delights(self,sentences:List[str])->List[Dict]:"""Extractpositivefeedback"""delights=[]forsentenceinsentences:sentence_lower=sentence.lower()forindicatorinself.delight_indicators:ifindicatorinsentence_lower:delights.append({'quote':sentence,'indicator':indicator,'strength':self._assess_strength(sentence_lower)})breakreturndelights[:10]def_extract_requests(self,sentences:List[str])->List[Dict]:"""Extractfeaturerequestsandsuggestions"""requests=[]forsentenceinsentences:sentence_lower=sentence.lower()forindicatorinself.request_indicators:ifindicatorinsentence_lower:requests.append({'quote':sentence,'type':self._classify_request(sentence_lower),'priority':self._assess_request_priority(sentence_lower)})breakreturnrequests[:10]def_extract_jtbd(self,text:str)->List[Dict]:"""ExtractJobstoBeDonepatterns"""jobs=[]forpatterninself.jtbd_patterns:matches=re.findall(pattern,text,re.IGNORECASE)formatchinmatches:ifisinstance(match,tuple):job='â†’'.join(match)else:job=matchjobs.append({'job':job,'pattern':pattern.patternifhasattr(pattern,'pattern')elsepattern})returnjobs[:5]def_calculate_sentiment(self,text:str)->Dict:"""Calculateoverallsentimentoftheinterview"""positive_count=sum(1forindinself.delight_indicatorsifindintext)negative_count=sum(1forindinself.pain_indicatorsifindintext)total=positive_count+negative_countiftotal==0:sentiment_score=0else:sentiment_score=(positive_count-negative_count)/totalifsentiment_score>0.3:sentiment_label='positive'elifsentiment_score<-0.3:sentiment_label='negative'else:sentiment_label='neutral'return{'score':round(sentiment_score,2),'label':sentiment_label,'positive_signals':positive_count,'negative_signals':negative_count}def_extract_themes(self,text:str)->List[str]:"""Extractkeythemesusingwordfrequency"""#Removecommonwordsstop_words={'the','a','an','and','or','but','in','on','at','to','for','of','with','by','from','as','is','was','are','were','been','be','have','has','had','do','does','did','will','would','could','should','may','might','must','can','shall','it','i','you','we','they','them','their'}#Extractmeaningfulwordswords=re.findall(r'\b[a-z]{4,}\b',text)meaningful_words=[wforwinwordsifwnotinstop_words]#Countfrequencyword_freq=Counter(meaningful_words)#Extractthemes(topfrequentmeaningfulwords)themes=[wordforword,countinword_freq.most_common(10)ifcount>=3]returnthemesdef_extract_key_quotes(self,sentences:List[str])->List[str]:"""Extractthemostinsightfulquotes"""scored_sentences=[]forsentenceinsentences:iflen(sentence)<20orlen(sentence)>200:continuescore=0sentence_lower=sentence.lower()#Scorebasedoninsightindicatorsifany(indinsentence_lowerforindinself.pain_indicators):score+=2ifany(indinsentence_lowerforindinself.request_indicators):score+=2if'because'insentence_lower:score+=1if'but'insentence_lower:score+=1if'?'insentence:score+=1ifscore>0:scored_sentences.append((score,sentence))#Sortbyscoreandreturntopquotesscored_sentences.sort(reverse=True)return[s[1]forsinscored_sentences[:5]]def_extract_metrics(self,text:str)->List[str]:"""Extractanymetricsornumbersmentioned"""metrics=[]#Findpercentagespercentages=re.findall(r'\d+%',text)metrics.extend(percentages)#Findtimemetricstime_metrics=re.findall(r'\d+\s*(?:hours?|minutes?|days?|weeks?|months?)',text,re.IGNORECASE)metrics.extend(time_metrics)#Findmoneymetricsmoney_metrics=re.findall(r'\$[\d,]+',text)metrics.extend(money_metrics)#Findgeneralnumberswithcontextnumber_contexts=re.findall(r'(\d+)\s+(\w+)',text)fornum,contextinnumber_contexts:ifcontext.lower()notin['the','a','an','and','or','of']:metrics.append(f"{num}{context}")returnlist(set(metrics))[:10]def_extract_competitors(self,text:str)->List[str]:"""Extractcompetitormentions"""#Commoncompetitorindicatorscompetitor_patterns=[r'(?:use|used|using|tried|trying|switchfrom|switchedfrom|insteadof)\s+(\w+)',r'(\w+)\s+(?:isbetter|worksbetter|iseasier)',r'comparedto\s+(\w+)',r'like\s+(\w+)',r'similarto\s+(\w+)',]competitors=set()forpatternincompetitor_patterns:matches=re.findall(pattern,text,re.IGNORECASE)competitors.update(matches)#Filteroutcommonwordscommon_words={'this','that','it','them','other','another','something'}competitors=[cforcincompetitorsifc.lower()notincommon_wordsandlen(c)>2]returnlist(competitors)[:5]def_assess_severity(self,text:str)->str:"""Assessseverityofpainpoint"""ifany(wordintextforwordin['very','extremely','really','totally','completely']):return'high'elifany(wordintextforwordin['somewhat','bit','little','slightly']):return'low'return'medium'def_assess_strength(self,text:str)->str:"""Assessstrengthofpositivefeedback"""ifany(wordintextforwordin['absolutely','definitely','really','very']):return'strong'return'moderate'def_classify_request(self,text:str)->str:"""Classifythetypeofrequest"""ifany(wordintextforwordin['ui','design','look','color','layout']):return'ui_improvement'elifany(wordintextforwordin['feature','add','new','build']):return'new_feature'elifany(wordintextforwordin['fix','bug','broken','work']):return'bug_fix'elifany(wordintextforwordin['faster','slow','performance','speed']):return'performance'return'general'def_assess_request_priority(self,text:str)->str:"""Assesspriorityofrequest"""ifany(wordintextforwordin['critical','urgent','asap','immediately','blocking']):return'critical'elifany(wordintextforwordin['need','important','should','must']):return'high'elifany(wordintextforwordin['nice','would','could','maybe']):return'low'return'medium'defaggregate_interviews(interviews:List[Dict])->Dict:"""Aggregateinsightsfrommultipleinterviews"""aggregated={'total_interviews':len(interviews),'common_pain_points':defaultdict(list),'common_requests':defaultdict(list),'jobs_to_be_done':[],'overall_sentiment':{'positive':0,'negative':0,'neutral':0},'top_themes':Counter(),'metrics_summary':set(),'competitors_mentioned':Counter()}forinterviewininterviews:#Aggregatepainpointsforpainininterview.get('pain_points',[]):indicator=pain.get('indicator','unknown')aggregated['common_pain_points'][indicator].append(pain['quote'])#Aggregaterequestsforrequestininterview.get('feature_requests',[]):req_type=request.get('type','general')aggregated['common_requests'][req_type].append(request['quote'])#AggregateJTBDaggregated['jobs_to_be_done'].extend(interview.get('jobs_to_be_done',[]))#Aggregatesentimentsentiment=interview.get('sentiment_score',{}).get('label','neutral')aggregated['overall_sentiment'][sentiment]+=1#Aggregatethemesforthemeininterview.get('key_themes',[]):aggregated['top_themes'][theme]+=1#Aggregatemetricsaggregated['metrics_summary'].update(interview.get('metrics_mentioned',[]))#Aggregatecompetitorsforcompetitorininterview.get('competitors_mentioned',[]):aggregated['competitors_mentioned'][competitor]+=1#Processaggregateddataaggregated['common_pain_points']=dict(aggregated['common_pain_points'])aggregated['common_requests']=dict(aggregated['common_requests'])aggregated['top_themes']=dict(aggregated['top_themes'].most_common(10))aggregated['metrics_summary']=list(aggregated['metrics_summary'])aggregated['competitors_mentioned']=dict(aggregated['competitors_mentioned'])returnaggregateddefformat_single_interview(analysis:Dict)->str:"""Formatsingleinterviewanalysis"""output=["="*60]output.append("CUSTOMERINTERVIEWANALYSIS")output.append("="*60)#Sentimentsentiment=analysis['sentiment_score']output.append(f"\nğŸ“ŠOverallSentiment:{sentiment['label'].upper()}")output.append(f"Score:{sentiment['score']}")output.append(f"Positivesignals:{sentiment['positive_signals']}")output.append(f"Negativesignals:{sentiment['negative_signals']}")#PainPointsifanalysis['pain_points']:output.append("\nğŸ”¥PainPointsIdentified:")fori,paininenumerate(analysis['pain_points'][:5],1):output.append(f"\n{i}.[{pain['severity'].upper()}]{pain['quote'][:100]}...")#FeatureRequestsifanalysis['feature_requests']:output.append("\nğŸ’¡FeatureRequests:")fori,reqinenumerate(analysis['feature_requests'][:5],1):output.append(f"\n{i}.[{req['type']}]Priority:{req['priority']}")output.append(f"\"{req['quote'][:100]}...\"")#JobstoBeDoneifanalysis['jobs_to_be_done']:output.append("\nğŸ¯JobstoBeDone:")fori,jobinenumerate(analysis['jobs_to_be_done'],1):output.append(f"{i}.{job['job']}")#KeyThemesifanalysis['key_themes']:output.append("\nğŸ·ï¸KeyThemes:")output.append(",".join(analysis['key_themes']))#KeyQuotesifanalysis['quotes']:output.append("\nğŸ’¬KeyQuotes:")fori,quoteinenumerate(analysis['quotes'][:3],1):output.append(f'{i}."{quote}"')#Metricsifanalysis['metrics_mentioned']:output.append("\nğŸ“ˆMetricsMentioned:")output.append(",".join(analysis['metrics_mentioned']))#Competitorsifanalysis['competitors_mentioned']:output.append("\nğŸ¢CompetitorsMentioned:")output.append(",".join(analysis['competitors_mentioned']))return"\n".join(output)defmain():importsysiflen(sys.argv)<2:print("Usage:pythoncustomer_interview_analyzer.py<interview_file.txt>")print("\nThistoolanalyzescustomerinterviewtranscriptstoextract:")print("-Painpointsandfrustrations")print("-Featurerequestsandsuggestions")print("-Jobstobedone")print("-Sentimentanalysis")print("-Keythemesandquotes")sys.exit(1)#Readinterviewtranscriptwithopen(sys.argv[1],'r')asf:interview_text=f.read()#Analyzeanalyzer=InterviewAnalyzer()analysis=analyzer.analyze_interview(interview_text)#Outputiflen(sys.argv)>2andsys.argv[2]=='json':print(json.dumps(analysis,indent=2))else:print(format_single_interview(analysis))if__name__=="__main__":main()