packageproviderimport("bytes""context""encoding/json""fmt""io""net/http""time")//AzureOpenAIProviderimplementstheProviderinterfaceforAzureOpenAI.//AzureusesadifferentURLpattern:{resource}.openai.azure.com/openai/deployments/{deployment}typeAzureOpenAIProviderstruct{configProviderConfigclient*http.ClientapiVersionstring}//NewAzureOpenAIProvidercreatesanewAzureOpenAIproviderconnector.//BaseURLshouldbe:https://{resource-name}.openai.azure.comfuncNewAzureOpenAIProvider(cfgProviderConfig)*AzureOpenAIProvider{ifcfg.Timeout==0{cfg.Timeout=120*time.Second}ifcfg.MaxRetries==0{cfg.MaxRetries=2}transport:=&http.Transport{MaxIdleConns:100,MaxIdleConnsPerHost:20,IdleConnTimeout:90*time.Second,}apiVersion:="2024-08-01-preview"ifv,ok:=cfg.Headers["api-version"];ok{apiVersion=v}return&AzureOpenAIProvider{config:cfg,client:&http.Client{Transport:transport,Timeout:cfg.Timeout,},apiVersion:apiVersion,}}func(p*AzureOpenAIProvider)Name()string{return"azure"}func(p*AzureOpenAIProvider)Models()[]string{iflen(p.config.Models)>0{returnp.config.Models}return[]string{"gpt-4o","gpt-4o-mini","gpt-4-turbo","gpt-4"}}//deploymentURLbuildstheAzuredeploymentURLforagivenmodel/deployment.//Azureformat:{base_url}/openai/deployments/{model}/chat/completions?api-version={version}func(p*AzureOpenAIProvider)deploymentURL(model,endpointstring)string{returnfmt.Sprintf("%s/openai/deployments/%s/%s?api-version=%s",p.config.BaseURL,model,endpoint,p.apiVersion)}func(p*AzureOpenAIProvider)ChatCompletion(ctxcontext.Context,req*ChatRequest)(*ChatResponse,error){req.Stream=false//Azuredoesn'tusethemodelfieldinthebodyâ€”thedeploymentnameisintheURLbodyReq:=*reqbodyReq.Model=""//RemovemodelfrombodyforAzurebody,err:=json.Marshal(bodyReq)iferr!=nil{returnnil,fmt.Errorf("marshalrequest:%w",err)}url:=p.deploymentURL(req.Model,"chat/completions")httpReq,err:=http.NewRequestWithContext(ctx,http.MethodPost,url,bytes.NewReader(body))iferr!=nil{returnnil,fmt.Errorf("createrequest:%w",err)}p.setHeaders(httpReq)resp,err:=p.client.Do(httpReq)iferr!=nil{returnnil,fmt.Errorf("azureopenairequestfailed:%w",err)}deferresp.Body.Close()ifresp.StatusCode!=http.StatusOK{respBody,_:=io.ReadAll(resp.Body)returnnil,fmt.Errorf("azureopenaireturnedstatus%d:%s",resp.StatusCode,string(respBody))}varchatRespChatResponseiferr:=json.NewDecoder(resp.Body).Decode(&chatResp);err!=nil{returnnil,fmt.Errorf("decoderesponse:%w",err)}return&chatResp,nil}func(p*AzureOpenAIProvider)ChatCompletionStream(ctxcontext.Context,req*ChatRequest)(Stream,error){req.Stream=truebodyReq:=*reqbodyReq.Model=""body,err:=json.Marshal(bodyReq)iferr!=nil{returnnil,fmt.Errorf("marshalrequest:%w",err)}url:=p.deploymentURL(req.Model,"chat/completions")httpReq,err:=http.NewRequestWithContext(ctx,http.MethodPost,url,bytes.NewReader(body))iferr!=nil{returnnil,fmt.Errorf("createrequest:%w",err)}p.setHeaders(httpReq)resp,err:=p.client.Do(httpReq)iferr!=nil{returnnil,fmt.Errorf("azureopenaistreamrequestfailed:%w",err)}ifresp.StatusCode!=http.StatusOK{respBody,_:=io.ReadAll(resp.Body)resp.Body.Close()returnnil,fmt.Errorf("azureopenaireturnedstatus%d:%s",resp.StatusCode,string(respBody))}returnNewHTTPStream(resp),nil}func(p*AzureOpenAIProvider)Embeddings(ctxcontext.Context,req*EmbeddingsRequest)(*EmbeddingsResponse,error){body,err:=json.Marshal(req)iferr!=nil{returnnil,fmt.Errorf("marshalrequest:%w",err)}url:=p.deploymentURL(req.Model,"embeddings")httpReq,err:=http.NewRequestWithContext(ctx,http.MethodPost,url,bytes.NewReader(body))iferr!=nil{returnnil,fmt.Errorf("createrequest:%w",err)}p.setHeaders(httpReq)resp,err:=p.client.Do(httpReq)iferr!=nil{returnnil,fmt.Errorf("azureopenaiembeddingsrequestfailed:%w",err)}deferresp.Body.Close()ifresp.StatusCode!=http.StatusOK{respBody,_:=io.ReadAll(resp.Body)returnnil,fmt.Errorf("azureopenaireturnedstatus%d:%s",resp.StatusCode,string(respBody))}varembRespEmbeddingsResponseiferr:=json.NewDecoder(resp.Body).Decode(&embResp);err!=nil{returnnil,fmt.Errorf("decoderesponse:%w",err)}return&embResp,nil}func(p*AzureOpenAIProvider)HealthCheck(ctxcontext.Context)HealthStatus{start:=time.Now()//Azurehealthcheck:listdeploymentsurl:=fmt.Sprintf("%s/openai/models?api-version=%s",p.config.BaseURL,p.apiVersion)httpReq,err:=http.NewRequestWithContext(ctx,http.MethodGet,url,nil)iferr!=nil{returnHealthStatus{Healthy:false,Error:err.Error(),LastCheck:time.Now()}}p.setHeaders(httpReq)resp,err:=p.client.Do(httpReq)latency:=time.Since(start)iferr!=nil{returnHealthStatus{Healthy:false,Latency:latency,Error:err.Error(),LastCheck:time.Now()}}deferresp.Body.Close()healthy:=resp.StatusCode==http.StatusOKerrMsg:=""if!healthy{errMsg=fmt.Sprintf("status%d",resp.StatusCode)}returnHealthStatus{Healthy:healthy,Latency:latency,LastCheck:time.Now(),Error:errMsg}}func(p*AzureOpenAIProvider)setHeaders(req*http.Request){req.Header.Set("Content-Type","application/json")//Azureusesapi-keyheaderinsteadofBearertokenreq.Header.Set("api-key",p.config.APIKey)fork,v:=rangep.config.Headers{ifk!="api-version"{//AlreadyhandledinURLreq.Header.Set(k,v)}}}