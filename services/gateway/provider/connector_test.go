packageproviderimport("context""encoding/json""io""net/http""net/http/httptest""strings""testing""time")//───ConstructorDefaults────────────────────────────────────funcTestOpenAIProviderDefaults(t*testing.T){p:=NewOpenAIProvider(ProviderConfig{APIKey:"sk-test"})ifp.config.BaseURL!="https://api.openai.com/v1"{t.Errorf("BaseURL=%q,wantopenaidefault",p.config.BaseURL)}ifp.config.Timeout!=120*time.Second{t.Errorf("Timeout=%v,want120s",p.config.Timeout)}ifp.config.MaxRetries!=2{t.Errorf("MaxRetries=%d,want2",p.config.MaxRetries)}ifp.client==nil{t.Error("HTTPclientisnil")}}funcTestOpenAIProviderCustomConfig(t*testing.T){p:=NewOpenAIProvider(ProviderConfig{BaseURL:"https://custom.openai.local/v1",APIKey:"sk-custom",Timeout:30*time.Second,MaxRetries:5,Models:[]string{"gpt-4o"},})ifp.config.BaseURL!="https://custom.openai.local/v1"{t.Errorf("BaseURLnotoverridden:%q",p.config.BaseURL)}ifp.config.Timeout!=30*time.Second{t.Errorf("Timeoutnotoverridden:%v",p.config.Timeout)}ifp.config.MaxRetries!=5{t.Errorf("MaxRetriesnotoverridden:%d",p.config.MaxRetries)}models:=p.Models()iflen(models)!=1||models[0]!="gpt-4o"{t.Errorf("Custommodelsnotrespected:%v",models)}}funcTestAnthropicProviderDefaults(t*testing.T){p:=NewAnthropicProvider(ProviderConfig{APIKey:"sk-ant-test"})ifp.config.BaseURL!="https://api.anthropic.com/v1"{t.Errorf("BaseURL=%q,wantanthropicdefault",p.config.BaseURL)}ifp.config.Timeout!=120*time.Second{t.Errorf("Timeout=%v,want120s",p.config.Timeout)}ifp.client==nil{t.Error("HTTPclientisnil")}}funcTestGeminiProviderDefaults(t*testing.T){p:=NewGeminiProvider(ProviderConfig{APIKey:"test-key"})if!strings.Contains(p.config.BaseURL,"generativelanguage.googleapis.com"){t.Errorf("BaseURL=%q,wantgoogleapis",p.config.BaseURL)}ifp.config.Timeout!=120*time.Second{t.Errorf("Timeout=%v,want120s",p.config.Timeout)}}funcTestAzureProviderDefaults(t*testing.T){p:=NewAzureOpenAIProvider(ProviderConfig{BaseURL:"https://my-resource.openai.azure.com",APIKey:"azure-key",})ifp.config.Timeout!=120*time.Second{t.Errorf("Timeout=%v,want120s",p.config.Timeout)}ifp.config.MaxRetries!=2{t.Errorf("MaxRetries=%d,want2",p.config.MaxRetries)}}funcTestCohereProviderDefaults(t*testing.T){p:=NewCohereProvider(ProviderConfig{APIKey:"co-test"})if!strings.Contains(p.config.BaseURL,"cohere"){t.Errorf("BaseURL=%q,wantcoheredefault",p.config.BaseURL)}ifp.config.Timeout!=120*time.Second{t.Errorf("Timeout=%v,want120s",p.config.Timeout)}}funcTestMistralProviderDefaults(t*testing.T){p:=NewMistralProvider(ProviderConfig{APIKey:"ms-test"})if!strings.Contains(p.config.BaseURL,"mistral"){t.Errorf("BaseURL=%q,wantmistraldefault",p.config.BaseURL)}ifp.client==nil{t.Error("HTTPclientisnil")}}funcTestTogetherProviderDefaults(t*testing.T){p:=NewTogetherProvider(ProviderConfig{APIKey:"tog-test"})if!strings.Contains(p.config.BaseURL,"together"){t.Errorf("BaseURL=%q,wanttogetherdefault",p.config.BaseURL)}}funcTestGroqProviderDefaults(t*testing.T){p:=NewGroqProvider(ProviderConfig{APIKey:"groq-test"})if!strings.Contains(p.config.BaseURL,"groq"){t.Errorf("BaseURL=%q,wantgroqdefault",p.config.BaseURL)}}funcTestOllamaProviderDefaults(t*testing.T){p:=NewOllamaProvider(ProviderConfig{})if!strings.Contains(p.config.BaseURL,"localhost:11434"){t.Errorf("BaseURL=%q,wantlocalhost:11434",p.config.BaseURL)}//Ollamatypicallyhasalongertimeoutifp.config.Timeout<120*time.Second{t.Errorf("Timeout=%v,want>=120sforlocalinference",p.config.Timeout)}}funcTestVLLMProviderDefaults(t*testing.T){p:=NewVLLMProvider(ProviderConfig{})if!strings.Contains(p.config.BaseURL,"localhost:8000"){t.Errorf("BaseURL=%q,wantlocalhost:8000",p.config.BaseURL)}}funcTestBedrockProviderDefaults(t*testing.T){p:=NewBedrockProvider(BedrockConfig{ProviderConfig:ProviderConfig{},Region:"us-east-1",AccessKey:"AKIA_TEST",SecretKey:"secret",})ifp.region!="us-east-1"{t.Errorf("Region=%q,wantus-east-1",p.region)}ifp.config.Timeout!=120*time.Second{t.Errorf("Timeout=%v,want120s",p.config.Timeout)}}//───Name()andModels()────────────────────────────────────funcTestProviderNames(t*testing.T){tests:=[]struct{providerProviderwantstring}{{NewOpenAIProvider(ProviderConfig{APIKey:"k"}),"openai"},{NewAnthropicProvider(ProviderConfig{APIKey:"k"}),"anthropic"},{NewGeminiProvider(ProviderConfig{APIKey:"k"}),"google"},{NewAzureOpenAIProvider(ProviderConfig{BaseURL:"https://x.openai.azure.com",APIKey:"k"}),"azure"},{NewCohereProvider(ProviderConfig{APIKey:"k"}),"cohere"},{NewMistralProvider(ProviderConfig{APIKey:"k"}),"mistral"},{NewTogetherProvider(ProviderConfig{APIKey:"k"}),"together"},{NewGroqProvider(ProviderConfig{APIKey:"k"}),"groq"},{NewOllamaProvider(ProviderConfig{}),"ollama"},{NewVLLMProvider(ProviderConfig{}),"vllm"},{NewBedrockProvider(BedrockConfig{Region:"us-east-1"}),"bedrock"},}for_,tt:=rangetests{t.Run(tt.want,func(t*testing.T){ifgot:=tt.provider.Name();got!=tt.want{t.Errorf("Name()=%q,want%q",got,tt.want)}})}}funcTestProviderDefaultModels(t*testing.T){//Eachprovidershouldreturnatleastonedefaultmodelwhennoneconfiguredproviders:=[]Provider{NewOpenAIProvider(ProviderConfig{APIKey:"k"}),NewAnthropicProvider(ProviderConfig{APIKey:"k"}),NewGeminiProvider(ProviderConfig{APIKey:"k"}),NewCohereProvider(ProviderConfig{APIKey:"k"}),NewMistralProvider(ProviderConfig{APIKey:"k"}),NewTogetherProvider(ProviderConfig{APIKey:"k"}),NewGroqProvider(ProviderConfig{APIKey:"k"}),NewOllamaProvider(ProviderConfig{}),NewVLLMProvider(ProviderConfig{}),}for_,p:=rangeproviders{t.Run(p.Name(),func(t*testing.T){models:=p.Models()iflen(models)==0{t.Errorf("%s.Models()returnedemptylist",p.Name())}})}}//───DetectProviderMapping──────────────────────────────────funcTestDetectProviderMapping(t*testing.T){tests:=[]struct{modelstringwantstring}{//OpenAImodels{"gpt-4o","openai"},{"gpt-4o-mini","openai"},{"gpt-3.5-turbo","openai"},{"gpt-4-turbo","openai"},{"o1-preview","openai"},{"text-embedding-3-small","openai"},{"text-embedding-ada-002","openai"},//Anthropicmodels{"claude-3-opus-20240229","anthropic"},{"claude-3-sonnet","anthropic"},{"claude-3-haiku","anthropic"},{"claude-opus-4","anthropic"},//Googlemodels{"gemini-1.5-pro","google"},{"gemini-pro","google"},//Azureprefix(prefix-basedpatternshavepriority){"azure/gpt-4o","azure"},//Mistralmodels{"mistral-7b","mistral"},{"mixtral-8x7b","mistral"},{"codestral-latest","mistral"},//Coheremodels{"command-r-plus","cohere"},//DeepSeek{"deepseek-chat","deepseek"},{"deepseek-coder","deepseek"},//Prefixedproviders(prefixpatternstakepriorityoversubstring){"together/llama-3-70b","together"},{"groq/llama-3-70b","groq"},{"ollama/llama3","ollama"},{"vllm/llama3","vllm"},//Bedrockmodels(prefixpatternscheckedfirst){"anthropic.claude-v2","bedrock"},{"amazon.titan-text-express","bedrock"},{"ai21.j2-ultra","bedrock"},//Unknown{"some-random-model","unknown"},{"","unknown"},}for_,tt:=rangetests{t.Run(tt.model,func(t*testing.T){got:=DetectProvider(tt.model)ifgot!=tt.want{t.Errorf("DetectProvider(%q)=%q,want%q",tt.model,got,tt.want)}})}}funcTestDetectProviderCaseInsensitive(t*testing.T){got:=DetectProvider("GPT-4o")ifgot!="openai"{t.Errorf("DetectProvider(GPT-4o)=%q,wantopenai",got)}got=DetectProvider("Claude-3-Opus")ifgot!="anthropic"{t.Errorf("DetectProvider(Claude-3-Opus)=%q,wantanthropic",got)}}//───Registry.GetForModel────────────────────────────────────funcTestRegistryGetForModel(t*testing.T){reg:=NewRegistry()mock:=&MockProvider{name:"openai"}reg.Register(mock)p,err:=reg.GetForModel("gpt-4o")iferr!=nil{t.Fatalf("GetForModel(gpt-4o)error:%v",err)}ifp.Name()!="openai"{t.Errorf("GetForModelreturned%q,wantopenai",p.Name())}}funcTestRegistryGetForModelUnknown(t*testing.T){reg:=NewRegistry()_,err:=reg.GetForModel("some-unknown-model")iferr==nil{t.Error("GetForModelshoulderrorforunknownmodel")}}funcTestRegistryGetForModelNotRegistered(t*testing.T){reg:=NewRegistry()//openaidetectedbutnotregistered_,err:=reg.GetForModel("gpt-4o")iferr==nil{t.Error("GetForModelshoulderrorwhenprovidernotregistered")}if!strings.Contains(err.Error(),"notregistered"){t.Errorf("Errorshouldmention'notregistered':%v",err)}}//───Registry.HealthCheckAll─────────────────────────────────funcTestRegistryHealthCheckAll(t*testing.T){reg:=NewRegistry()mock1:=&mockHealthProvider{name:"openai",healthResult:HealthStatus{Healthy:true,LastCheck:time.Now()}}mock2:=&mockHealthProvider{name:"anthropic",healthResult:HealthStatus{Healthy:false,Error:"down",LastCheck:time.Now()}}reg.Register(mock1)reg.Register(mock2)results:=reg.HealthCheckAll(context.Background())iflen(results)!=2{t.Fatalf("HealthCheckAllreturned%dresults,want2",len(results))}if!results["openai"].Healthy{t.Error("openaishouldbehealthy")}ifresults["anthropic"].Healthy{t.Error("anthropicshouldbeunhealthy")}}//───ChatCompletionviahttptest──────────────────────────────funcnewMockOpenAIServer(t*testing.T)*httptest.Server{t.Helper()returnhttptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){switch{caser.URL.Path=="/chat/completions"&&r.Method==http.MethodPost://Verifyauthheaderauth:=r.Header.Get("Authorization")if!strings.HasPrefix(auth,"Bearer"){w.WriteHeader(http.StatusUnauthorized)return}//ReadandvalidaterequestbodyvarreqChatRequestiferr:=json.NewDecoder(r.Body).Decode(&req);err!=nil{w.WriteHeader(http.StatusBadRequest)return}resp:=ChatResponse{ID:"chatcmpl-test123",Object:"chat.completion",Created:time.Now().Unix(),Model:req.Model,Choices:[]Choice{{Index:0,Message:ChatMessage{Role:"assistant",Content:"Hellofromtest!"},FinishReason:"stop",},},Usage:Usage{PromptTokens:10,CompletionTokens:5,TotalTokens:15,},}w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(resp)caser.URL.Path=="/embeddings"&&r.Method==http.MethodPost:resp:=EmbeddingsResponse{Object:"list",Data:[]EmbeddingData{{Object:"embedding",Embedding:[]float64{0.1,0.2,0.3},Index:0},},Model:"text-embedding-3-small",Usage:EmbeddingsUsage{PromptTokens:5,TotalTokens:5},}w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(resp)caser.URL.Path=="/models"&&r.Method==http.MethodGet:w.Header().Set("Content-Type","application/json")_,_=w.Write([]byte(`{"object":"list","data":[]}`))default:w.WriteHeader(http.StatusNotFound)}}))}funcTestOpenAIChatCompletion(t*testing.T){srv:=newMockOpenAIServer(t)defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test-key",})maxTokens:=100resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},MaxTokens:&maxTokens,})iferr!=nil{t.Fatalf("ChatCompletionerror:%v",err)}ifresp.ID!="chatcmpl-test123"{t.Errorf("ResponseID=%q,wantchatcmpl-test123",resp.ID)}iflen(resp.Choices)!=1{t.Fatalf("Choices=%d,want1",len(resp.Choices))}ifresp.Choices[0].FinishReason!="stop"{t.Errorf("FinishReason=%q,wantstop",resp.Choices[0].FinishReason)}ifresp.Usage.TotalTokens!=15{t.Errorf("TotalTokens=%d,want15",resp.Usage.TotalTokens)}}funcTestOpenAIChatCompletionServerError(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.WriteHeader(http.StatusInternalServerError)_,_=w.Write([]byte(`{"error":"internalservererror"}`))}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})_,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr==nil{t.Fatal("Expectederrorfor500response")}if!strings.Contains(err.Error(),"500"){t.Errorf("Errorshouldcontainstatuscode500:%v",err)}}funcTestOpenAIChatCompletionContextCancelled(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){//Simulateslowresponsetime.Sleep(2*time.Second)w.WriteHeader(http.StatusOK)}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})ctx,cancel:=context.WithTimeout(context.Background(),100*time.Millisecond)defercancel()_,err:=p.ChatCompletion(ctx,&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr==nil{t.Fatal("Expectederrorforcancelledcontext")}}funcTestOpenAIChatCompletionStreamSetsStreamFlag(t*testing.T){varreceivedStreamboolsrv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){varreqChatRequestiferr:=json.NewDecoder(r.Body).Decode(&req);err==nil{receivedStream=req.Stream}w.Header().Set("Content-Type","text/event-stream")_,_=w.Write([]byte("data:{\"choices\":[{\"delta\":{\"content\":\"Hi\"}}]}\n\n"))}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})stream,err:=p.ChatCompletionStream(context.Background(),&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr!=nil{t.Fatalf("ChatCompletionStreamerror:%v",err)}deferstream.Close()if!receivedStream{t.Error("streamflagshouldbetrueinrequesttoprovider")}//Readonechunkchunk,err:=stream.Next()iferr!=nil{t.Fatalf("stream.Next()error:%v",err)}iflen(chunk)==0{t.Error("Expectednon-emptychunk")}}funcTestOpenAIEmbeddings(t*testing.T){srv:=newMockOpenAIServer(t)defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})resp,err:=p.Embeddings(context.Background(),&EmbeddingsRequest{Model:"text-embedding-3-small",Input:"Helloworld",})iferr!=nil{t.Fatalf("Embeddingserror:%v",err)}iflen(resp.Data)!=1{t.Fatalf("Datalen=%d,want1",len(resp.Data))}iflen(resp.Data[0].Embedding)!=3{t.Errorf("Embeddinglen=%d,want3",len(resp.Data[0].Embedding))}}funcTestOpenAIEmbeddingsServerError(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.WriteHeader(http.StatusTooManyRequests)_,_=w.Write([]byte(`{"error":"ratelimited"}`))}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})_,err:=p.Embeddings(context.Background(),&EmbeddingsRequest{Model:"text-embedding-3-small",Input:"Helloworld",})iferr==nil{t.Fatal("Expectederrorfor429response")}if!strings.Contains(err.Error(),"429"){t.Errorf("Errorshouldcontain429:%v",err)}}//───OpenAIHealthCheck──────────────────────────────────────funcTestOpenAIHealthCheckHealthy(t*testing.T){srv:=newMockOpenAIServer(t)defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})status:=p.HealthCheck(context.Background())if!status.Healthy{t.Errorf("HealthCheckshouldbehealthy,goterror:%s",status.Error)}ifstatus.Latency<0{t.Error("Latencyshouldbenon-negative")}}funcTestOpenAIHealthCheckUnhealthy(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.WriteHeader(http.StatusServiceUnavailable)}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})status:=p.HealthCheck(context.Background())ifstatus.Healthy{t.Error("HealthCheckshouldbeunhealthyfor503")}ifstatus.Error==""{t.Error("Errorshouldbenon-empty")}}//───AuthHeaderVerification────────────────────────────────funcTestOpenAIAuthHeaders(t*testing.T){varcapturedHeadershttp.Headersrv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){capturedHeaders=r.Header.Clone()w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{Choices:[]Choice{{Message:ChatMessage{Role:"assistant",Content:"ok"},FinishReason:"stop"}},})}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test-12345",Headers:map[string]string{"X-Custom":"value"},})_,_=p.ChatCompletion(context.Background(),&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"test"}},})ifcapturedHeaders.Get("Authorization")!="Bearersk-test-12345"{t.Errorf("Authheader=%q,want'Bearersk-test-12345'",capturedHeaders.Get("Authorization"))}ifcapturedHeaders.Get("Content-Type")!="application/json"{t.Errorf("Content-Type=%q,wantapplication/json",capturedHeaders.Get("Content-Type"))}ifcapturedHeaders.Get("X-Custom")!="value"{t.Errorf("Customheadermissing:%q",capturedHeaders.Get("X-Custom"))}}funcTestAnthropicAuthHeaders(t*testing.T){varcapturedHeadershttp.Headersrv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){capturedHeaders=r.Header.Clone()w.Header().Set("Content-Type","application/json")//ReturnAnthropic-formatresponse_,_=w.Write([]byte(`{"id":"msg-test","type":"message","role":"assistant","content":[{"type":"text","text":"ok"}],"model":"claude-3-opus","stop_reason":"end_turn","usage":{"input_tokens":10,"output_tokens":5}}`))}))defersrv.Close()p:=NewAnthropicProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-ant-test-key",})_,_=p.ChatCompletion(context.Background(),&ChatRequest{Model:"claude-3-opus",Messages:[]ChatMessage{{Role:"user",Content:"test"}},})ifcapturedHeaders.Get("x-api-key")!="sk-ant-test-key"{t.Errorf("Anthropicauthheader=%q,want'sk-ant-test-key'",capturedHeaders.Get("x-api-key"))}if!strings.Contains(capturedHeaders.Get("anthropic-version"),"2023"){t.Errorf("anthropic-versionheadermissingorwrong:%q",capturedHeaders.Get("anthropic-version"))}}funcTestMistralAuthHeaders(t*testing.T){varcapturedAuthstringsrv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){capturedAuth=r.Header.Get("Authorization")w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{Choices:[]Choice{{Message:ChatMessage{Role:"assistant",Content:"ok"},FinishReason:"stop"}},})}))defersrv.Close()p:=NewMistralProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"ms-key"})_,_=p.ChatCompletion(context.Background(),&ChatRequest{Model:"mistral-7b",Messages:[]ChatMessage{{Role:"user",Content:"test"}},})ifcapturedAuth!="Bearerms-key"{t.Errorf("Mistralauth=%q,want'Bearerms-key'",capturedAuth)}}//───AnthropicChatCompletion────────────────────────────────funcTestAnthropicChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){//VerifyAnthropicendpointifr.URL.Path!="/messages"{t.Errorf("Unexpectedpath:%s",r.URL.Path)w.WriteHeader(http.StatusNotFound)return}//Readrequestbodytoverifycorrectformatbody,_:=io.ReadAll(r.Body)varreqmap[string]interface{}_=json.Unmarshal(body,&req)//Anthropicuses"model"attoplevelif_,ok:=req["model"];!ok{t.Error("Anthropicrequestmissing'model'field")}w.Header().Set("Content-Type","application/json")_,_=w.Write([]byte(`{"id":"msg-test","type":"message","role":"assistant","content":[{"type":"text","text":"HellofromAnthropic!"}],"model":"claude-3-opus","stop_reason":"end_turn","usage":{"input_tokens":10,"output_tokens":8}}`))}))defersrv.Close()p:=NewAnthropicProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-ant"})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"claude-3-opus",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr!=nil{t.Fatalf("AnthropicChatCompletionerror:%v",err)}ifresp==nil{t.Fatal("Responseisnil")}iflen(resp.Choices)==0{t.Fatal("Nochoicesinresponse")}ifresp.Usage.PromptTokens!=10{t.Errorf("PromptTokens=%d,want10",resp.Usage.PromptTokens)}}funcTestAnthropicChatCompletionError(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.WriteHeader(http.StatusBadRequest)_,_=w.Write([]byte(`{"error":{"type":"invalid_request_error","message":"badrequest"}}`))}))defersrv.Close()p:=NewAnthropicProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-ant"})_,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"claude-3-opus",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr==nil{t.Fatal("Expectederrorfor400response")}}//───GeminiChatCompletion───────────────────────────────────funcTestGeminiChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){//Geminiusespathlike/models/<model>:generateContentif!strings.Contains(r.URL.Path,"generateContent")&&!strings.Contains(r.URL.Path,"chat/completions"){//AcceptbothpatternssincesomeimplementationsuseOpenAI-compatw.WriteHeader(http.StatusNotFound)return}w.Header().Set("Content-Type","application/json")//ReturnGemini-formatresponse_,_=w.Write([]byte(`{"candidates":[{"content":{"parts":[{"text":"HellofromGemini!"}],"role":"model"},"finishReason":"STOP"}],"usageMetadata":{"promptTokenCount":5,"candidatesTokenCount":4,"totalTokenCount":9}}`))}))defersrv.Close()p:=NewGeminiProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"gemini-key"})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"gemini-1.5-pro",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr!=nil{t.Fatalf("GeminiChatCompletionerror:%v",err)}ifresp==nil{t.Fatal("Responseisnil")}}//───OpenAI-compatibleproviders(Together,Groq,Mistral)──funcTestTogetherChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{ID:"toget-test",Model:"together/llama-3-70b",Choices:[]Choice{{Index:0,Message:ChatMessage{Role:"assistant",Content:"Together!"},FinishReason:"stop"},},Usage:Usage{PromptTokens:3,CompletionTokens:1,TotalTokens:4},})}))defersrv.Close()p:=NewTogetherProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"tog-key"})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"together/llama-3-70b",Messages:[]ChatMessage{{Role:"user",Content:"Hi"}},})iferr!=nil{t.Fatalf("TogetherChatCompletionerror:%v",err)}iflen(resp.Choices)==0{t.Error("Nochoices")}}funcTestGroqChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{ID:"groq-test",Model:"groq/llama-3-70b",Choices:[]Choice{{Index:0,Message:ChatMessage{Role:"assistant",Content:"Groqfast!"},FinishReason:"stop"},},Usage:Usage{PromptTokens:3,CompletionTokens:2,TotalTokens:5},})}))defersrv.Close()p:=NewGroqProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"groq-key"})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"groq/llama-3-70b",Messages:[]ChatMessage{{Role:"user",Content:"Hi"}},})iferr!=nil{t.Fatalf("GroqChatCompletionerror:%v",err)}iflen(resp.Choices)==0{t.Error("Nochoices")}}funcTestMistralChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{ID:"ms-test",Model:"mistral-7b",Choices:[]Choice{{Index:0,Message:ChatMessage{Role:"assistant",Content:"Bonjour!"},FinishReason:"stop"},},Usage:Usage{PromptTokens:3,CompletionTokens:1,TotalTokens:4},})}))defersrv.Close()p:=NewMistralProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"ms-key"})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"mistral-7b",Messages:[]ChatMessage{{Role:"user",Content:"Hi"}},})iferr!=nil{t.Fatalf("MistralChatCompletionerror:%v",err)}iflen(resp.Choices)==0{t.Error("Nochoices")}}//───OllamaandvLLM(localinference)───────────────────────funcTestOllamaChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{ID:"ollama-test",Model:"ollama/llama3",Choices:[]Choice{{Index:0,Message:ChatMessage{Role:"assistant",Content:"LocalAI!"},FinishReason:"stop"},},Usage:Usage{PromptTokens:3,CompletionTokens:2,TotalTokens:5},})}))defersrv.Close()p:=NewOllamaProvider(ProviderConfig{BaseURL:srv.URL})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"ollama/llama3",Messages:[]ChatMessage{{Role:"user",Content:"Hi"}},})iferr!=nil{t.Fatalf("OllamaChatCompletionerror:%v",err)}iflen(resp.Choices)==0{t.Error("Nochoices")}}funcTestVLLMChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.Header().Set("Content-Type","application/json")_=json.NewEncoder(w).Encode(ChatResponse{ID:"vllm-test",Model:"vllm/llama3",Choices:[]Choice{{Index:0,Message:ChatMessage{Role:"assistant",Content:"vLLM!"},FinishReason:"stop"},},Usage:Usage{PromptTokens:3,CompletionTokens:1,TotalTokens:4},})}))defersrv.Close()p:=NewVLLMProvider(ProviderConfig{BaseURL:srv.URL})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"vllm/llama3",Messages:[]ChatMessage{{Role:"user",Content:"Hi"}},})iferr!=nil{t.Fatalf("vLLMChatCompletionerror:%v",err)}iflen(resp.Choices)==0{t.Error("Nochoices")}}//───StreamErrorHandling───────────────────────────────────funcTestOpenAIStreamServerError(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){w.WriteHeader(http.StatusBadGateway)_,_=w.Write([]byte(`{"error":"badgateway"}`))}))defersrv.Close()p:=NewOpenAIProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"sk-test"})_,err:=p.ChatCompletionStream(context.Background(),&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr==nil{t.Fatal("Expectederrorfor502streamresponse")}if!strings.Contains(err.Error(),"502"){t.Errorf("Errorshouldcontain502:%v",err)}}//───CohereChatCompletion───────────────────────────────────funcTestCohereChatCompletion(t*testing.T){srv:=httptest.NewServer(http.HandlerFunc(func(whttp.ResponseWriter,r*http.Request){//Cohereusesitsownformatbutconnectortranslatesw.Header().Set("Content-Type","application/json")_,_=w.Write([]byte(`{"text":"HellofromCohere!","generation_id":"co-test","meta":{"tokens":{"input_tokens":5,"output_tokens":4}}}`))}))defersrv.Close()p:=NewCohereProvider(ProviderConfig{BaseURL:srv.URL,APIKey:"co-key"})resp,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"command-r-plus",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr!=nil{t.Fatalf("CohereChatCompletionerror:%v",err)}ifresp==nil{t.Fatal("Responseisnil")}}//───InvalidURL/ConnectionErrors─────────────────────────funcTestOpenAIConnectionError(t*testing.T){p:=NewOpenAIProvider(ProviderConfig{BaseURL:"http://127.0.0.1:1",APIKey:"sk-test",Timeout:1*time.Second,})_,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"gpt-4o",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr==nil{t.Fatal("Expectedconnectionerror")}}funcTestAnthropicConnectionError(t*testing.T){p:=NewAnthropicProvider(ProviderConfig{BaseURL:"http://127.0.0.1:1",APIKey:"sk-ant",Timeout:1*time.Second,})_,err:=p.ChatCompletion(context.Background(),&ChatRequest{Model:"claude-3-opus",Messages:[]ChatMessage{{Role:"user",Content:"Hello"}},})iferr==nil{t.Fatal("Expectedconnectionerror")}}//───MockProviderextensions(basedefinedinprovider_test.go)──//TheMockProviderinprovider_test.goisuseddirectly.Fortests//thatneedcustomhealthresults,weusemockHealthProviderbelow.typemockHealthProviderstruct{namestringhealthResultHealthStatus}func(m*mockHealthProvider)Name()string{returnm.name}func(m*mockHealthProvider)ChatCompletion(ctxcontext.Context,req*ChatRequest)(*ChatResponse,error){return&ChatResponse{Choices:[]Choice{{Message:ChatMessage{Role:"assistant",Content:"mock"},FinishReason:"stop"}},},nil}func(m*mockHealthProvider)ChatCompletionStream(ctxcontext.Context,req*ChatRequest)(Stream,error){returnnil,nil}func(m*mockHealthProvider)Embeddings(ctxcontext.Context,req*EmbeddingsRequest)(*EmbeddingsResponse,error){return&EmbeddingsResponse{},nil}func(m*mockHealthProvider)HealthCheck(ctxcontext.Context)HealthStatus{returnm.healthResult}func(m*mockHealthProvider)Models()[]string{return[]string{"mock-model"}}