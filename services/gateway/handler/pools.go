packagehandlerimport("bytes""sync")//───BufferPools─────────────────────────────────────────────//bufPoolprovidesreusablebytes.BufferinstancesforJSON//marshal/unmarshal.Avoidsper-request[]byteallocations.varbufPool=sync.Pool{New:func()any{returnbytes.NewBuffer(make([]byte,0,4096))},}//getBufreturnsaresetbufferfromthepool.funcgetBuf()*bytes.Buffer{buf:=bufPool.Get().(*bytes.Buffer)buf.Reset()returnbuf}//putBufreturnsabuffertothepool.//Discardsoversizedbuffers(>64KiB)topreventpoolbloat.funcputBuf(buf*bytes.Buffer){ifbuf.Cap()>65536{return//letGCcollectoversizedbuffers}bufPool.Put(buf)}//───TypedResponseStructs───────────────────────────────────//Replacesmap[string]interface{}allocationswithzero-allocstructs.//errorDetailistheinnererrorobject.typeerrorDetailstruct{Typestring`json:"type"`Messagestring`json:"message"`Hintstring`json:"hint,omitempty"`Codestring`json:"code,omitempty"`}//errorResponseistheOpenAI-compatibleerrorenvelope.typeerrorResponsestruct{ErrorerrorDetail`json:"error"`}//modelEntryrepresentsasinglemodelinGET/v1/models.typemodelEntrystruct{IDstring`json:"id"`Objectstring`json:"object"`Providerstring`json:"provider"`OwnedBystring`json:"owned_by"`}//modelsResponseistheresponseforGET/v1/models.typemodelsResponsestruct{Objectstring`json:"object"`Data[]modelEntry`json:"data"`}//dryRunResponseistheresponsefordry-runmode.typedryRunResponsestruct{DryRunbool`json:"dry_run"`Modelstring`json:"model"`Providerstring`json:"provider"`EstimatedTokensestimatedTokensT`json:"estimated_tokens"`Messagestring`json:"message"`}typeestimatedTokensTstruct{PromptTokensint`json:"prompt_tokens"`MaxCompletionint`json:"max_completion"`TotalEstimateint`json:"total_estimated"`}//providerHealthEntryrepresentsasingleproviderhealthstatus.typeproviderHealthEntrystruct{Healthybool`json:"healthy"`LatencyMsint64`json:"latency_ms"`LastCheckstring`json:"last_check"`Errorstring`json:"error"`}