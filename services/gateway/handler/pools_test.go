packagehandler_testimport("bytes""context""encoding/json""io""net/http""net/http/httptest""strings""testing""github.com/AlfredDev/alfred/services/gateway/handler""github.com/AlfredDev/alfred/services/gateway/provider""github.com/rs/zerolog")//───PoolTests───────────────────────────────────────────────funcTestWriteError_TypedStruct(t*testing.T){logger:=zerolog.Nop()reg:=provider.NewRegistry()h:=handler.NewProxyHandler(logger,reg)rr:=httptest.NewRecorder()req:=httptest.NewRequest("POST","/v1/chat/completions",nil)//Triggeravalidationerrorh.ChatCompletions(rr,req)ifrr.Code!=http.StatusBadRequest{t.Fatalf("expected400,got%d",rr.Code)}//VerifytheerrorresponseisproperlystructuredJSONvarrespstruct{Errorstruct{Typestring`json:"type"`Messagestring`json:"message"`}`json:"error"`}iferr:=json.NewDecoder(rr.Body).Decode(&resp);err!=nil{t.Fatalf("failedtodecodeerrorresponse:%v",err)}ifresp.Error.Type!="invalid_request"{t.Errorf("expectederrortype'invalid_request',got%q",resp.Error.Type)}ifresp.Error.Message==""{t.Error("expectednon-emptyerrormessage")}}funcTestModels_TypedStruct(t*testing.T){logger:=zerolog.Nop()reg:=provider.NewRegistry()//RegisteramockprovidermockProv:=&mockModelsProvider{name:"test-provider",models:[]string{"model-a","model-b"},}reg.Register(mockProv)h:=handler.NewProxyHandler(logger,reg)rr:=httptest.NewRecorder()req:=httptest.NewRequest("GET","/v1/models",nil)h.Models(rr,req)ifrr.Code!=http.StatusOK{t.Fatalf("expected200,got%d",rr.Code)}varrespstruct{Objectstring`json:"object"`Data[]struct{IDstring`json:"id"`Objectstring`json:"object"`Providerstring`json:"provider"`OwnedBystring`json:"owned_by"`}`json:"data"`}iferr:=json.NewDecoder(rr.Body).Decode(&resp);err!=nil{t.Fatalf("decodeerror:%v",err)}ifresp.Object!="list"{t.Errorf("expectedobject'list',got%q",resp.Object)}iflen(resp.Data)!=2{t.Fatalf("expected2models,got%d",len(resp.Data))}ifresp.Data[0].ID!="model-a"||resp.Data[0].Provider!="test-provider"{t.Errorf("unexpectedfirstmodel:%+v",resp.Data[0])}}funcTestDryRun_TypedStruct(t*testing.T){logger:=zerolog.Nop()reg:=provider.NewRegistry()h:=handler.NewProxyHandler(logger,reg)body:=`{"model":"gpt-4","messages":[{"role":"user","content":"Helloworld"}]}`rr:=httptest.NewRecorder()req:=httptest.NewRequest("POST","/v1/chat/completions",strings.NewReader(body))req.Header.Set("X-Alfred-DryRun","true")h.ChatCompletions(rr,req)ifrr.Code!=http.StatusOK{t.Fatalf("expected200,got%d",rr.Code)}varrespstruct{DryRunbool`json:"dry_run"`Modelstring`json:"model"`Providerstring`json:"provider"`EstimatedTokensstruct{PromptTokensint`json:"prompt_tokens"`MaxCompletionint`json:"max_completion"`TotalEstimateint`json:"total_estimated"`}`json:"estimated_tokens"`Messagestring`json:"message"`}iferr:=json.NewDecoder(rr.Body).Decode(&resp);err!=nil{t.Fatalf("decodeerror:%v",err)}if!resp.DryRun{t.Error("expecteddry_run=true")}ifresp.Model!="gpt-4"{t.Errorf("expectedmodel'gpt-4',got%q",resp.Model)}ifresp.EstimatedTokens.PromptTokens<=0{t.Error("expectedpositiveprompttokenestimate")}}funcTestPooledBufferEncoding(t*testing.T){//VerifythatpooledbufferencodingproducesvalidJSON//byexercisingmultipleencode/decodecyclesfori:=0;i<100;i++{logger:=zerolog.Nop()reg:=provider.NewRegistry()h:=handler.NewProxyHandler(logger,reg)rr:=httptest.NewRecorder()req:=httptest.NewRequest("POST","/v1/chat/completions",strings.NewReader(`{"model":"","messages":[]}`))h.ChatCompletions(rr,req)//ShouldreturnvalidJSON(eithersuccessorerror)varrawjson.RawMessagebody:=rr.Body.Bytes()iflen(body)==0{continue//someresponsesmaybeempty}iferr:=json.Unmarshal(body,&raw);err!=nil{t.Fatalf("iteration%d:responseisnotvalidJSON:%v\nbody:%s",i,err,body)}}}//───Benchmarks───────────────────────────────────────────────funcBenchmarkWriteError_Pooled(b*testing.B){logger:=zerolog.Nop()reg:=provider.NewRegistry()h:=handler.NewProxyHandler(logger,reg)b.ReportAllocs()b.ResetTimer()fori:=0;i<b.N;i++{rr:=httptest.NewRecorder()req:=httptest.NewRequest("POST","/v1/chat/completions",nil)h.ChatCompletions(rr,req)}}funcBenchmarkChatCompletions_Decode(b*testing.B){logger:=zerolog.Nop()reg:=provider.NewRegistry()h:=handler.NewProxyHandler(logger,reg)body:=`{"model":"gpt-4","messages":[{"role":"user","content":"Helloworld,thisisatest."}]}`b.ReportAllocs()b.ResetTimer()fori:=0;i<b.N;i++{rr:=httptest.NewRecorder()req:=httptest.NewRequest("POST","/v1/chat/completions",strings.NewReader(body))h.ChatCompletions(rr,req)}}funcBenchmarkDryRun_TypedVsMap(b*testing.B){logger:=zerolog.Nop()reg:=provider.NewRegistry()h:=handler.NewProxyHandler(logger,reg)body:=`{"model":"gpt-4","messages":[{"role":"user","content":"Helloworld"}]}`b.ReportAllocs()b.ResetTimer()fori:=0;i<b.N;i++{rr:=httptest.NewRecorder()req:=httptest.NewRequest("POST","/v1/chat/completions",strings.NewReader(body))req.Header.Set("X-Alfred-DryRun","true")h.ChatCompletions(rr,req)}}funcBenchmarkModels_TypedVsMap(b*testing.B){logger:=zerolog.Nop()reg:=provider.NewRegistry()mockProv:=&mockModelsProvider{name:"openai",models:[]string{"gpt-4","gpt-3.5-turbo","gpt-4o"},}reg.Register(mockProv)h:=handler.NewProxyHandler(logger,reg)b.ReportAllocs()b.ResetTimer()fori:=0;i<b.N;i++{rr:=httptest.NewRecorder()req:=httptest.NewRequest("GET","/v1/models",nil)h.Models(rr,req)}}//───MockProvider───────────────────────────────────────────typemockModelsProviderstruct{namestringmodels[]string}func(m*mockModelsProvider)Name()string{returnm.name}func(m*mockModelsProvider)Models()[]string{returnm.models}func(m*mockModelsProvider)ChatCompletion(_context.Context,_*provider.ChatRequest)(*provider.ChatResponse,error){return&provider.ChatResponse{},nil}func(m*mockModelsProvider)ChatCompletionStream(_context.Context,_*provider.ChatRequest)(provider.Stream,error){returnnil,nil}func(m*mockModelsProvider)Embeddings(_context.Context,_*provider.EmbeddingsRequest)(*provider.EmbeddingsResponse,error){return&provider.EmbeddingsResponse{},nil}func(m*mockModelsProvider)HealthCheck(_context.Context)provider.HealthStatus{returnprovider.HealthStatus{Healthy:true}}//Ensureunusedimportsareconsumedvar_=bytes.NewBuffervar_=io.Copy